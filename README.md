Qonto Skill Test
==============================

## 1. Overview

Using synthetic dataset generated by the PaySim mobile money simulator, build a machine learning model to detect fraudulent movements and prevent account takeover fraud (ATO), also known as account compromise.

## 2. Motivation

Detect fraudulent movements is one of the main issue of any banking company, as Qonto is growing pretty fast building a detection tool is necessary. 

## 3. Success metrics

There is many ways of using the output of this product and we could / have to build an appropriate success metric for each of them.
We can assume that it's a real time topic and that we may not want to put some transactions on hold to be manually reviewed before being accepted.
The obvious business goal is to reduce the number of transactions that will be cashed out by blocking them and so save money.

## 4. Requirements & Constraints

We could split the constraints in 2 parts, the ones from the model himself (training time, performances...) and the ones from the pipeline (latency, data need in the API call...). Most of the requirements have to be discussed and validated with the business (and / or tech) stackeholders.  
In this product we are talking about fraud detection and the end goal is to score any incoming transaction.  

__Model Requirements :__
* Training Time : We won't retrain the model with each new transaction but use a pre trained model to do the predictions so this is not really a constraint here. Even a complex machine learning model won't be that long to train and we can do it whenever we need.
* Performances : The end goal is to block (without any humain check) the high risk predicted transactions so we have to ensure a very high performance. In this use case we can't have too many false positive because the customer experience will suffer a lot. The KPI to monitore here is the precision, we may need to do a rought tradeoff to ensure excellent precision even if the recall suffers in return.
* Latency : As explained no issue on the training part in term of computing time, but this is not the same deal on the scoring side. The model has to be simple enought to ensure a really quick responding time (between 20 and 100ms).  

__Pipeline Requirements :__
* Data : To be able to score the transaction we will need some information about it. In the end the model has to be called with some meta data about the transaction (transaction type, amount...).
* Latency : As it's a real time plugged product every call has to be fast, the target is to have a pipeline running in less than 100ms.  

## 5. Methodology

### 5.1. Problem statement

This is a fraud detection problem so it could be advised using either supervised or unsupervised way. In this case we will train a supervised model to score the transactions. 

### 5.2. Data

To train the model we will use the dataset directly from Kaggle, create some features and select the ones interesting 
after the EDA.

### 5.3. Techniques

As it is a test I will try some different machine learning models and select the one with the best results in the 
final training script, the XGB model is the one finally selected.  
Thanks to the EDA I kept only the transactions type Transfer and Cashout because the others ones have never been flagged
as fraudulent. I create the feature about the day and hour of the transactions and fix the balances that seems to not
be correct (amount > 0 but origin and dest balances still equal to 0).  
We don't need to scale the data for this kind of model so that's all for the preparation side.

### 5.4. Experimentation & Validation

Some feature analysis have been done and you can find it in the notebooks EDA and Visualization. To save some time 
the plots are stored in the outputs/reports/figure/ folder and the HTML reports are also stored in the folder outputs/reports/.  
Of course it's a very unbalanced dataset, but we can remove some useless kind of transactions that have never been fraudulent.  

To quickly have an idea of what kind of models could be great I used a powerful tool called pycaret that run a bunch
of models and give you a performance overview. In the Modeling notebook I focus on 2 models, XGB and Linear Regression 
(even if it not seems to be the best it was the opportunity to test some dataset balancing and scaling).  
To evaluate this models I used a classic ROC curve and confusion matrix.

## 7. Appendix

### 7.1. Alternatives

I choose the classification way to solve this problem but we could try an other powerful technique using auto encoders
that are also a classic in the fraud detection problems.  
These networks are slitly more difficult to build than classic ML models and the classic ones already have strong 
performances so I kept this way.

### 7.2. Experiment Results

All the experiment results can be find either in the pycaret plot stored in the reports folder or in the modeling notebook.

### 7.3. Performance benchmarks

Share any performance benchmarks you ran (e.g., throughput vs. latency vs. instance size/count).

### 7.4 What could be great to add

As this is a test choices has to be made and we could / have to add some stuff to reach the production level.  
Mainly the Unit Test, the feature creation and preparation was kind of straight forward so it was not really necessary 
but we definitly have to add some later on. We could also use ML Flow to monitore the model performances and DVC to ensure
a version control of the data. We could also add some Great Expectation checks to ensure the quality of the data.  

And the biggest part is that it's supposed to be a real time model and for this test purpose we treat it as a batch problem.
In a production environment we would have to build an API or use some cloud hosting to do the inference.

--------

Contributions [welcome](https://github.com/eugeneyan/ml-design-docs/pulls)!
<p><small>Project based on the <a target="_blank" href="https://drivendata.github.io/cookiecutter-data-science/">cookiecutter data science project template</a>. #cookiecutterdatascience</small></p>
